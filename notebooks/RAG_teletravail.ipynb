{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b55acc-0e5c-4d30-8b60-50070eb0307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook from https://medium.com/@thakermadhav/build-your-own-rag-with-mistral-7b-and-langchain-97d0c92fa146\n",
    "!pip install -q torch datasets\n",
    "!pip install -q accelerate==0.21.0 \\\n",
    "                peft==0.4.0 \\\n",
    "                bitsandbytes==0.40.2 \\\n",
    "                transformers==4.31.0 \\\n",
    "                trl==0.4.7\n",
    "!pip install -q scipy langchain transformers playwright html2text sentence_transformers faiss-gpu\n",
    "!pip install -q --upgrade git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860479f-f9d0-4162-9701-aeb4da44f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install > /dev/null\n",
    "!playwright install-deps > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8eba08-2a0d-43a0-ae6c-79035327b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923862f9-6c52-4509-b85f-b464c7ba0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "  AutoTokenizer, \n",
    "  AutoModelForCausalLM, \n",
    "  BitsAndBytesConfig,\n",
    "  pipeline\n",
    ")\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True\n",
    "\n",
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    cache_dir=\".\"\n",
    ")\n",
    "#load_in_4bits=True)\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    ")\n",
    "\n",
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb3129-2b6a-4819-9b68-ad0552cb23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "import pandas as pd\n",
    "PARQUET_FILE=\"Accords/echantillon_public_Mathilde.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e9f65-5314-4091-b2eb-cb3592a8b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(PARQUET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f4c3e-99d2-46ff-b97c-39ba7ffa5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "\n",
    "### [ROLE] Role: Vous êtes un expert juridique des accords d'entreprise sans compétence de programmation informatique, seulement la lecture et la compréhension des textes. Tu ne connais aucun langage de programmation, ni les expressions régulières.\n",
    "\n",
    "\n",
    "### [INST] Instruction: Votre travail consiste à peupler et mettre à jour une base des données nécessaires pour réaliser des études économétriques poussées sur le télétravail.\n",
    "        Pour cela, vous devez prendre les textes des accords d'entreprise dans lesquelles figurent les informations à jour que l'on vous fourni, et d'extraire précisément l'information spécifique dont vous avez besoin.\n",
    "        Vous ne devez extraire que le nombre, et uniquement le nombre. Le nombre peut être écrit en lettres ou en chiffres. (exemple : deux ou 2 )\n",
    "        Si vous ne trouver pas la réponse dans le texte vous devez le dire et ne pas chercher à en fournir un autre nombre.\n",
    "        Avant de répondre, vérifier que la réponse se trouve bien dans le texte indiqué.\n",
    "        Impératif pour votre raisonnement : Déconnecter les liens entre les périodicités (semaine, mois, trimestre, année)! Faire comme si les semaines, les mois, les trimestres et les années sont des concepts indépendants : dans un mois, il y a donc 0 semaine ; dans un trimestre, 0 mois et 0 semaine; dans une année, 0 trimestre, 0 mois et 0 semaine !\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e7965-223c-49ed-bea1-5c0dd89a6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc8e16-8943-4e71-8a43-7342eeae75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "def guess_reponse_booleenne(reponse):\n",
    "    reponse_booleenne=None\n",
    "    if reponse[\"text\"].startswith(\"\\nOui\") or reponse[\"text\"].startswith(\"Oui\") :\n",
    "        reponse_booleenne=1\n",
    "    elif reponse[\"text\"].startswith(\"\\nNon\") or reponse[\"text\"].startswith(\"Non\") :\n",
    "        reponse_booleenne=0\n",
    "    return reponse_booleenne\n",
    "\n",
    "def guess_reponse_durée(reponse):\n",
    "    reponse_booleenne=None\n",
    "    if \"indéterminée\" in reponse[\"text\"].lower() :\n",
    "        reponse_booleenne=0\n",
    "    elif \"déterminée\" in reponse[\"text\"].lower():\n",
    "        reponse_booleenne=1\n",
    "    return reponse_booleenne\n",
    "\n",
    "def guess_reponse_nombre(reponse):\n",
    "    reponse_nombre=None\n",
    "    REGEX=r\".*nombre=(\\d+)\"\n",
    "    numbers=re.findall(REGEX,reponse[\"text\"])\n",
    "    if numbers:\n",
    "        reponse_nombre=numbers[0]\n",
    "    return reponse_nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e6397-10db-4fad-9abc-b1780fcbdd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_DUREE=\"S'il est fait mention d'une durée de l'accord, est-ce que l'accord est à durée déterminée ou à durée indéterminée ? déterminée=1 ou indéterminée=0 ou NA?\"\n",
    "Q_REVERS=\"S'il est fait mention d'une clause et d'un article de réversibilité, est-ce que l'accord a une clause ou un article de réversibilité ? Oui=1 ou non=0 ou NA?\"\n",
    "Q_ADAPT=\"S'il est fait mention d'une période d'adaptation, est-ce que l'accord comprend une période d'adaptation ? Oui=1 ou non=0 ou NA?\"\n",
    "Q_TTREG=\"Est-ce qu'au moins un paragraphe mentionne du télétravail régulier ?\"\n",
    "Q_TTOCA=\"Est-ce qu'au moins un paragraphe mentionne du télétravail occasionnel ?\"\n",
    "Q_TTEXC=\"Est-ce qu'au moins un paragraphe mentionne du télétravail exceptionnel ?\"\n",
    "Q_DISPOSPERQTHENCEINTE=\"Est-ce qu'au moins un paragraphe mentionne des dispositifs spéciaux pour les travailleurs en situation de handicap, les femmes enceintes, les séniors ou les personnes présentant des fragilités ou des problèmes de santé ?\"\n",
    "Q_MONTANT_CAVIARDE=\"Est-ce qu'au moins un paragraphe mentionne un nombre sans le donner exactement, mais sous forme illisible ?\"\n",
    "Q_TELETRAVAIL_FLEX_SANS_LIMITE=\"Est-ce qu'au moins un paragraphe suggère une liberté totale dans le choix des jours de télétravail, hormis quelques contraintes de présence ?\"\n",
    "Q_TT_REG_NOMBRE_FORMULE=Q_TTREG+\"Si oui, combien de formules (exemples de formule : si temps plein et temps partiel = 2, si choix entre 1 à 3 jours de télétravail régulier = 3) sont proposées pour du télétravail régulier ? Retourne à la fin 'nombre=max(tes réponses)'\"\n",
    "PERIODICITE={\"MOIS\":\"mois\",\"TRIM\":\"trimestre\",\"ANNEE\":\"année\", \"SEM\":\"semaine\"}\n",
    "PERIODICITE2={\"JOUR\":\"jour\",\"MOIS\":\"mois\",\"TRIM\":\"trimestre\",\"ANNEE\":\"année\", \"SEM\":\"semaine\"}\n",
    "Q_COMPE=\"Est-ce qu'au moins un paragraphe mentionne une indemnité spécialement pour l'achat d'équipements ?\"\n",
    "Q_COMPE_NOMBRE=Q_COMPE+\"Si oui, sélectionne seulement les paragraphes mentionnant une indemnité spécialement pour l'achat d'équipements et s'il existe donne le montant lié de l'indemnité d'équipement. Si oui, retourne à la fin 'nombre=max(ta réponse)'\"\n",
    "Q_EQUIPEMENT=\"Est-ce qu'au moins un paragraphe mentionne un équipement de télétravail fourni ?\"\n",
    "Q_COMPS=\"Est-ce qu'au moins un paragraphe mentionne explicitement une indemnité de sujétion (dans le cas où l'employeur impose le télétravail, ce dernier indemnise l'employé) ?\"\n",
    "Q_COMPS_NOMBRE=Q_COMPS+\"Si oui, sélectionne seulement les paragraphes mentionnant une indemnité de sujétion dans le cas où l'employeur impose le télétravail et s'il existe donne le montant lié de l'indemnité de sujétion dans le cas où l'employeur impose le télétravail. Si oui, retourne à la fin 'nombre=max(ta réponse)'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6654b6-813d-40f6-bae7-f3f68ff1c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model(rag_chain,num_dossier):\n",
    "    dict_reponse=dict()\n",
    "    dict_reponse[\"num_dossier\"]=num_dossier\n",
    "    text=\"\"\n",
    "    reponse= rag_chain.invoke(Q_DISPOSPERQTHENCEINTE)\n",
    "    text+=\"Q_DISPOSPERQTHENCEINTE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"DISPOSPERQTHENCEINTE\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_MONTANT_CAVIARDE)\n",
    "    text+=\"Q_MONTANT_CAVIARDE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"MONTANT_CAVIARDE\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_TELETRAVAIL_FLEX_SANS_LIMITE)\n",
    "    text+=\"Q_TELETRAVAIL_FLEX_SANS_LIMITE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"TELETRAVAIL_FLEX_SANS_LIMITE\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_TT_REG_NOMBRE_FORMULE)\n",
    "    text+=\"Q_TT_REG_NOMBRE_FORMULE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"TT_REG_NOMBRE_FORMULE\"]=guess_reponse_nombre(reponse)\n",
    "    reponse= rag_chain.invoke(Q_DUREE)\n",
    "    text+=\"Q_DUREE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"DUREE\"]=guess_reponse_durée(reponse)\n",
    "    reponse= rag_chain.invoke(Q_REVERS)\n",
    "    text+=\"Q_REVERS:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"REVERS\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_ADAPT)\n",
    "    text+=\"Q_ADAPT:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"ADAPT\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_TTREG)\n",
    "    text+=\"Q_TTREG:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"TTREG\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_TTOCA)\n",
    "    text+=\"Q_TTOCA:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"TTOCA\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_TTEXC)\n",
    "    text+=\"Q_TTEXC:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"TTEXC\"]=guess_reponse_booleenne(reponse)\n",
    "    for (k,v) in PERIODICITE.items():\n",
    "        Q_TT=f\"Hors jours supplémentaires ou exceptionnels, est-ce qu'au moins un paragraphe mentionne un nombre de jour de télétravail maximum autorisé explicitement exprimé par {v} ?\"\n",
    "        reponse= rag_chain.invoke(Q_TT)\n",
    "        text+=f\"Q_TT{k}:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"TT{k}\"]=guess_reponse_booleenne(reponse)\n",
    "        #Q_TT_NOMBRE=f\"Extrait le nombre de jour de télétravail maximum autorisé explicitement exprimé par {v} seulement à partir du texte suivant : {text_reponse}\"\n",
    "        Q_TT_NOMBRE=Q_TT+f\"Si oui, quel est le nombre de jour de télétravail supplémentaires explicitement exprimé et nécessairement et seulement exprimé par {v} pour des dispositions spéciales. Si oui, retourne à la fin 'nombre=max(tes réponses)'\"\n",
    "        reponse= rag_chain.invoke(Q_TT_NOMBRE)\n",
    "        text+=f\"Q_TT{k}_NOMBRE:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"TT{k}_NOMBRE\"]=guess_reponse_nombre(reponse)\n",
    "    for (k,v) in PERIODICITE.items():\n",
    "        Q_TTOCA_PERIOD=f\"Dans le cadre du télétravail occasionnel, est-ce qu'au moins un paragraphe mentionne un nombre de jour de télétravail maximum autorisé explicitement exprimé par {v} ?\"\n",
    "        reponse= rag_chain.invoke(Q_TTOCA_PERIOD)\n",
    "        text+=f\"TTOCA{k}:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"TTOCA{k}\"]=guess_reponse_booleenne(reponse)\n",
    "        Q_TTOCA_NOMBRE=Q_TTOCA_PERIOD+f\"Si oui, quel est le nombre de jour de télétravail occasionnel explicitement exprimé et nécessairement et seulement exprimé par {v}. Si oui, retourne à la fin 'nombre=max(tes réponses)'\"\n",
    "        reponse= rag_chain.invoke(Q_TTOCA_NOMBRE)\n",
    "        text+=f\"Q_TTOCA_{k}_NOMBRE:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"TTOCA_{k}_NOMBRE\"]=guess_reponse_nombre(reponse)\n",
    "    for (k,v) in PERIODICITE.items():\n",
    "        Q_PRESJOUR=f\"Est-ce qu'au moins un paragraphe mentionne un nombre de jour de présence obligatoire sur site minimum explicitement exprimé par {v} ?\"\n",
    "        reponse= rag_chain.invoke(Q_PRESJOUR)\n",
    "        text+=f\"Q_PRESJOUR{k}:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"TTPRESJOUR{k}\"]=guess_reponse_booleenne(reponse)\n",
    "        Q_PRESJOUR_NOMBRE=Q_PRESJOUR+f\"Si oui, sélectionne seulement les paragraphes mentionnant un nombre de jour de présence obligatoire sur site minimum explicitement exprimé par {v} et s'il existe donne le nombre de jour de présence obligatoire sur site minimum explicitement exprimé par {v}. Si oui, retourne à la fin 'nombre=max(tes réponses)'\"\n",
    "        reponse= rag_chain.invoke(Q_PRESJOUR_NOMBRE)\n",
    "        text+=f\"Q_PRESJOUR{k}_NOMBRE:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"PRESJOUR{k}_NOMBRE\"]=guess_reponse_nombre(reponse)\n",
    "    for (k,v) in PERIODICITE2.items():\n",
    "        Q_COMP=f\"Hors indemnité d'équipement, est-ce qu'au moins un paragraphe mentionne une indemnité forfaitaire explicitement exprimée par {v} ?\"\n",
    "        reponse= rag_chain.invoke(Q_COMP)\n",
    "        text+=f\"Q_COMP{k}:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"COMP{k}\"]=guess_reponse_booleenne(reponse)\n",
    "        Q_COMP_NOMBRE=Q_COMP+f\"Si oui, sélectionne en interne seulement les paragraphes mentionnant une indemnité forfaitaire explicitement exprimé par {v}, puis s'il existe donne le montant explicitement exprimé par {v}. Si oui, retourne à la fin 'nombre=max(ta réponse)'\"\n",
    "        reponse= rag_chain.invoke(Q_COMP_NOMBRE)\n",
    "        text+=f\"Q_COMP{k}_NOMBRE:\"+reponse[\"text\"] + \"\\n\"\n",
    "        dict_reponse[f\"COMP{k}_NOMBRE\"]=guess_reponse_nombre(reponse)\n",
    "        if \"MOIS\" in k:\n",
    "            Q_COMP_NOMBRE_BASE=Q_COMP+f\"Si oui, sélectionne en interne seulement les paragraphes mentionnant une indemnité forfaitaire explicitement exprimé par {v}, puis s'il existe plusieurs montants explicitement exprimé par {v}, par nombre de jour. Si oui, retourne à la fin 'nombre=base_mensuelle_pour_un_jour_de_teletravail(ta réponse)'\"\n",
    "            reponse= rag_chain.invoke(Q_COMP_NOMBRE_BASE)\n",
    "            text+=f\"Q_COMP{k}_BASE_NOMBRE:\"+reponse[\"text\"] + \"\\n\"\n",
    "            dict_reponse[f\"COMP{k}_BASE_NOMBRE\"]=guess_reponse_nombre(reponse)\n",
    "    reponse= rag_chain.invoke(Q_COMPE)\n",
    "    text+=\"Q_COMPE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"COMPE\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_COMPE_NOMBRE)\n",
    "    text+=\"Q_COMPE_NOMBRE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"COMPE_NOMBRE\"]=guess_reponse_nombre(reponse)\n",
    "    reponse= rag_chain.invoke(Q_EQUIPEMENT)\n",
    "    text+=\"Q_EQUIPEMENT:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"EQUIPEMENT\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_COMPS)\n",
    "    text+=\"Q_COMPS:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"COMPS\"]=guess_reponse_booleenne(reponse)\n",
    "    reponse= rag_chain.invoke(Q_COMPS_NOMBRE)\n",
    "    text+=\"Q_COMPS_NOMBRE:\"+reponse[\"text\"] + \"\\n\"\n",
    "    dict_reponse[\"COMPS_NOMBRE\"]=guess_reponse_nombre(reponse)\n",
    "    return dict_reponse,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de9f12-d3b6-4aa5-8603-df16fe199823",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_TRANSLATION={'DISPOSPERQTHENCEINTE': \"dispositif_special_rqth_maternite_senior\",\n",
    " 'MONTANT_CAVIARDE': \"montant_caviarde\",\n",
    " 'TELETRAVAIL_FLEX_SANS_LIMITE': \"teletravail_regulier_flexible_sans_limite\",\n",
    " 'TT_REG_NOMBRE_FORMULE': \"nombre_formules_teletravail_regulier\",\n",
    " 'DUREE': \"duree_application\",\n",
    " 'REVERS': \"presence_clause_reversibilite\",\n",
    " 'ADAPT': \"periode_adaptation\",\n",
    " 'TTREG': \"teletravail_regulier\",\n",
    " 'TTOCA': \"teletravail_occasionnel\",\n",
    " 'TTEXC': \"teletravail_exceptionnel\",\n",
    " 'TTMOIS': \"mention_teletravail_par_mois\",\n",
    " 'TTMOIS_NOMBRE': \"nombre_jours_teletravail_mois\",\n",
    " 'TTTRIM': \"mention_teletravail_par_trimestre\",\n",
    " 'TTTRIM_NOMBRE': \"nombre_jours_teletravail_trimestre\",\n",
    " 'TTANNEE': \"mention_teletravail_par_annuel\",\n",
    " 'TTANNEE_NOMBRE': \"nombre_jours_teletravail_annuel\",\n",
    " 'TTSEM': \"mention_teletravail_par_semaine\",\n",
    " 'TTSEM_NOMBRE': \"nombre_jours_teletravail_semaine\",\n",
    " 'TTOCAMOIS': \"occas_mention_teletravail_par_mois\",\n",
    " 'TTOCA_MOIS_NOMBRE': \"occas_nombre_jours_teletravail_mois\",\n",
    " 'TTOCATRIM': \"occas_mention_teletravail_par_trimestre\",\n",
    " 'TTOCA_TRIM_NOMBRE': \"occas_nombre_jours_teletravail_trimestre\",\n",
    " 'TTOCAANNEE': \"occas_mention_teletravail_par_annuel\",\n",
    " 'TTOCA_ANNEE_NOMBRE': \"occas_nombre_jours_teletravail_annuel\",\n",
    " 'TTOCASEM': \"occas_mention_teletravail_par_semaine\",\n",
    " 'TTOCA_SEM_NOMBRE': \"occas_nombre_jours_teletravail_semaine\",\n",
    " 'TTPRESJOURMOIS': \"mention_jour_presence_par_mois\",\n",
    " 'PRESJOURMOIS_NOMBRE': \"nombre_jour_presence_par_mois\",\n",
    " 'TTPRESJOURTRIM': \"mention_jour_presence_par_trimestre\",\n",
    " 'PRESJOURTRIM_NOMBRE': \"nombre_jour_presence_par_trimestre\",\n",
    " 'TTPRESJOURANNEE': \"mention_jour_presence_par_annuel\",\n",
    " 'PRESJOURANNEE_NOMBRE': \"nombre_jour_presence_par_annuel\",\n",
    " 'TTPRESJOURSEM': \"mention_jour_presence_par_semaine\",\n",
    " 'PRESJOURSEM_NOMBRE': \"nombre_jour_presence_par_semaine\",\n",
    " 'COMPJOUR': \"mention_indemnisation_journaliere\",\n",
    " 'COMPJOUR_NOMBRE': \"indemnisation_journaliere\",\n",
    " 'COMPMOIS': \"mention_indemnisation_mensuelle\",\n",
    " 'COMPMOIS_NOMBRE': \"indemnisation_mensuelle\",\n",
    " 'COMPMOIS_BASE_NOMBRE': \"indemnisation_base_mensuelle_pour_un_jour_par_semaine\",\n",
    " 'COMPTRIM': \"mention_indemnisation_trimestrielle\",\n",
    " 'COMPTRIM_NOMBRE': \"indemnisation_trimestrielle\",\n",
    " 'COMPANNEE': \"mention_indemnisation_annuelle\",\n",
    " 'COMPANNEE_NOMBRE': \"indemnisation_annuelle\",\n",
    " 'COMPSEM': \"mention_indemnisation_semaine\",\n",
    " 'COMPSEM_NOMBRE': \"indemnisation_semaine\",\n",
    " 'COMPE': \"mention_indemnisation_equipement\",\n",
    " 'COMPE_NOMBRE': \"indemnisation_equipement\",\n",
    " 'COMPS': \"mention_indemnite_sujetion\",\n",
    " 'COMPS_NOMBRE': \"montant_indemnite_sujetion\",\n",
    " 'EQUIPEMENT': \"equipement_fourni\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f7678-1d49-4b9b-b43b-174df0008bbd",
   "metadata": {},
   "source": [
    "# Boucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42e89b-c55e-43fa-9954-c4330e0945b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index,(num_dossier,accord)) in df.iterrows():\n",
    "    print(index,num_dossier)\n",
    "    with open(f\"{num_dossier}.txt\",\"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(accord)\n",
    "\n",
    "    loader = TextLoader(f\"{num_dossier}.txt\", encoding='utf8')\n",
    "    docs=loader.load()\n",
    "    \n",
    "\n",
    "\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    \n",
    "    # Chunk text\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, \n",
    "                                          chunk_overlap=100)\n",
    "    chunked_documents = text_splitter.split_documents(docs_transformed)\n",
    "    \n",
    "    # Load chunked documents into the FAISS index\n",
    "    db = FAISS.from_documents(chunked_documents, \n",
    "                              HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
    "    \n",
    "    retriever = db.as_retriever()\n",
    "    \n",
    "    rag_chain = ( \n",
    "     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | llm_chain\n",
    "    )\n",
    "    dict_reponse,text=process_model(rag_chain,num_dossier)\n",
    "    with open(f\"{num_dossier}_response.txt\",\"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "    df2=pd.DataFrame.from_dict(dict_reponse,orient=\"index\")\n",
    "    df2=df2.transpose().rename(columns=VAR_TRANSLATION)\n",
    "    df2.to_csv(f\"{num_dossier}.csv\")\n",
    "    df2.to_parquet(f\"{num_dossier}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
